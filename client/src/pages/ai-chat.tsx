import { useState, useRef, useEffect } from 'react';
import { useLocation } from 'wouter';
import { useMutation, useQuery, useQueryClient } from '@tanstack/react-query';
import { apiRequest } from '@/lib/queryClient';
import { Button } from '@/components/ui/button';
import { Textarea } from '@/components/ui/textarea';
import { useToast } from '@/hooks/use-toast';

interface ChatMessage {
  role: 'user' | 'assistant';
  content: string;
  timestamp: Date;
}

export default function AiChat() {
  const [, setLocation] = useLocation();
  const { toast } = useToast();
  const queryClient = useQueryClient();
  
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [currentMessage, setCurrentMessage] = useState('');
  const [isListening, setIsListening] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [conversationActive, setConversationActive] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  
  const recognitionRef = useRef<any>(null);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);

  // Load chat history
  const { data: chatHistory } = useQuery({
    queryKey: ['/api/chat/history'],
    retry: false,
  });

  useEffect(() => {
    if (chatHistory && typeof chatHistory === 'object' && 'messages' in chatHistory && Array.isArray((chatHistory as any).messages)) {
      setMessages((chatHistory as any).messages.map((msg: any) => ({
        ...msg,
        timestamp: new Date(msg.timestamp)
      })));
    }
  }, [chatHistory]);

  const chatMutation = useMutation({
    mutationFn: async (message: string) => {
      const response = await fetch('/api/chat', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ message }),
      });
      if (!response.ok) throw new Error('Failed to send message');
      return await response.json();
    },
    onSuccess: async (response: any) => {
      const assistantMessage: ChatMessage = {
        role: 'assistant',
        content: response.response,
        timestamp: new Date(),
      };
      setMessages(prev => [...prev, assistantMessage]);
      
      // Auto-speak if conversation is active
      if (conversationActive) {
        await speakText(response.response);
      }
      
      queryClient.invalidateQueries({ queryKey: ['/api/chat/history'] });
    },
  });

  const clearChat = async () => {
    try {
      const response = await fetch('/api/chat/clear', { method: 'POST' });
      if (!response.ok) throw new Error('Failed to clear chat');
      setMessages([]);
      endConversation();
      queryClient.invalidateQueries({ queryKey: ['/api/chat/history'] });
    } catch (error) {
      console.error('Failed to clear chat:', error);
    }
  };

  const handleQuickQuestion = async (question: string) => {
    const userMessage: ChatMessage = {
      role: 'user',
      content: question,
      timestamp: new Date(),
    };
    setMessages(prev => [...prev, userMessage]);
    await chatMutation.mutateAsync(question);
  };

  const handleSubmit = async (e: React.FormEvent) => {
    e.preventDefault();
    if (!currentMessage.trim() || chatMutation.isPending) return;

    const userMessage: ChatMessage = {
      role: 'user',
      content: currentMessage.trim(),
      timestamp: new Date(),
    };
    setMessages(prev => [...prev, userMessage]);
    const messageToSend = currentMessage.trim();
    setCurrentMessage('');
    
    await chatMutation.mutateAsync(messageToSend);
  };

  // Voice conversation functions
  const startListening = () => {
    const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      toast({
        title: '–ì–ª–∞—Å–æ–≤–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ –Ω–µ —Å–µ –ø–æ–¥–¥—ä—Ä–∂–∞',
        description: isMobile 
          ? '–ò–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ Chrome –Ω–∞ Android –∏–ª–∏ Safari –Ω–∞ iOS.'
          : '–í–∞—à–∏—è—Ç –±—Ä–∞—É–∑—ä—Ä –Ω–µ –ø–æ–¥–¥—ä—Ä–∂–∞ –≥–ª–∞—Å–æ–≤–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ. –û–ø–∏—Ç–∞–π—Ç–µ —Å Chrome –∏–ª–∏ Safari.',
        variant: 'destructive',
      });
      return;
    }

    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }

    setIsListening(true);
    resetConversationTimeout();
    
    const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognitionRef.current = recognition;
    
    recognition.lang = 'bg-BG';
    recognition.interimResults = false;
    recognition.maxAlternatives = 1;
    recognition.continuous = false;
    
    // Mobile-specific settings
    if (isMobile) {
      // On mobile, use shorter timeouts
      recognition.grammars = null;
    }

    recognition.onresult = async (event: any) => {
      const transcript = event.results[0][0].transcript;
      setCurrentMessage(transcript);
      setIsListening(false);
      
      if (transcript.trim()) {
        // If conversation is active, send immediately
        // If not active, wait 5 seconds for user to complete thought
        const delay = conversationActive ? 0 : 5000;
        
        setTimeout(async () => {
          const userMessage: ChatMessage = {
            role: 'user',
            content: transcript.trim(),
            timestamp: new Date(),
          };
          setMessages(prev => [...prev, userMessage]);
          setCurrentMessage('');
          
          await chatMutation.mutateAsync(transcript.trim());
        }, delay);
      }
    };

    recognition.onerror = (event: any) => {
      console.error('Speech recognition error:', event.error);
      setIsListening(false);
      
      let errorMessage = '–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –≥–ª–∞—Å–æ–≤–æ—Ç–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ';
      switch (event.error) {
        case 'not-allowed':
          errorMessage = '–î–æ—Å—Ç—ä–ø—ä—Ç –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –µ –æ—Ç–∫–∞–∑–∞–Ω. –ú–æ–ª—è, —Ä–∞–∑—Ä–µ—à–µ—Ç–µ –¥–æ—Å—Ç—ä–ø –≤ –±—Ä–∞—É–∑—ä—Ä–∞ —Å–∏.';
          endConversation();
          break;
        case 'no-speech':
          errorMessage = '–ù–µ –±–µ—à–µ –æ—Ç–∫—Ä–∏—Ç–∞ —Ä–µ—á. –û–ø–∏—Ç–∞–π—Ç–µ –æ—Ç–Ω–æ–≤–æ.';
          break;
        case 'audio-capture':
          errorMessage = '–ü—Ä–æ–±–ª–µ–º —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞. –ü—Ä–æ–≤–µ—Ä–µ—Ç–µ –¥–∞–ª–∏ –µ —Å–≤—ä—Ä–∑–∞–Ω –ø—Ä–∞–≤–∏–ª–Ω–æ.';
          break;
        case 'network':
          errorMessage = '–ú—Ä–µ–∂–æ–≤–∞ –≥—Ä–µ—à–∫–∞. –ü—Ä–æ–≤–µ—Ä–µ—Ç–µ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç –≤—Ä—ä–∑–∫–∞—Ç–∞ —Å–∏.';
          break;
      }
      
      if (event.error !== 'no-speech') {
        toast({
          title: '–ì—Ä–µ—à–∫–∞ —Å –≥–ª–∞—Å–∞',
          description: errorMessage,
          variant: 'destructive',
        });
      }
    };

    recognition.onend = () => {
      setIsListening(false);
    };

    try {
      recognition.start();
    } catch (error) {
      console.error('Failed to start speech recognition:', error);
      setIsListening(false);
      toast({
        title: '–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ',
        description: '–ù–µ –º–æ–∂–∞ –¥–∞ —Å–µ —Å—Ç–∞—Ä—Ç–∏—Ä–∞ –≥–ª–∞—Å–æ–≤–æ—Ç–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ.',
        variant: 'destructive',
      });
    }
  };

  const resetConversationTimeout = () => {
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
    }
    
    // End conversation after 5 seconds of inactivity if no conversation is active, 7 seconds if active
    const timeoutDelay = conversationActive ? 7000 : 5000;
    timeoutRef.current = setTimeout(() => {
      endConversation();
    }, timeoutDelay);
  };

  const endConversation = () => {
    setConversationActive(false);
    setIsListening(false);
    setIsRecording(false);
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
    if (timeoutRef.current) {
      clearTimeout(timeoutRef.current);
    }
    window.speechSynthesis.cancel();
    setIsSpeaking(false);
  };

  const handleVoiceRecording = async () => {
    // Detailed browser support check for mobile
    const hasSpeechRecognition = 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window;
    const isMobile = /Android|webOS|iPhone|iPad|iPod|BlackBerry|IEMobile|Opera Mini/i.test(navigator.userAgent);
    const isIOS = /iPad|iPhone|iPod/.test(navigator.userAgent);
    const isAndroid = /Android/i.test(navigator.userAgent);
    
    console.log('Detailed browser support check:', {
      hasSpeechRecognition,
      isMobile,
      isIOS,
      isAndroid,
      userAgent: navigator.userAgent,
      isSecureContext: window.isSecureContext,
      location: window.location.href,
      mediaDevicesSupported: navigator.mediaDevices ? true : false
    });

    // Enhanced mobile browser checks
    if (!hasSpeechRecognition) {
      let browserMessage = '–ë—Ä–∞—É–∑—ä—Ä—ä—Ç –Ω–µ –ø–æ–¥–¥—ä—Ä–∂–∞ –≥–ª–∞—Å–æ–≤–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ.';
      
      if (isIOS) {
        browserMessage = '–ò–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ Safari –Ω–∞ iOS –∑–∞ –Ω–∞–π-–¥–æ–±—Ä–∞ –ø–æ–¥–¥—Ä—ä–∂–∫–∞ –Ω–∞ –≥–ª–∞—Å–æ–≤–æ—Ç–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ.';
      } else if (isAndroid) {
        browserMessage = '–ò–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ Chrome –Ω–∞ Android —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –∑–∞ –≥–ª–∞—Å–æ–≤–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ.';
      } else if (isMobile) {
        browserMessage = '–û–ø–∏—Ç–∞–π—Ç–µ —Å Chrome –Ω–∞ Android –∏–ª–∏ Safari –Ω–∞ iOS —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ.';
      }
      
      toast({
        title: '–ì–ª–∞—Å—ä—Ç –Ω–µ —Å–µ –ø–æ–¥–¥—ä—Ä–∂–∞',
        description: browserMessage,
        variant: 'destructive',
      });
      return;
    }

    // Enhanced HTTPS and permission checks for mobile
    if (isMobile) {
      if (!window.isSecureContext) {
        toast({
          title: '–ò–∑–∏—Å–∫–≤–∞ —Å–µ —Å–∏–≥—É—Ä–Ω–∞ –≤—Ä—ä–∑–∫–∞',
          description: '–ì–ª–∞—Å–æ–≤–æ—Ç–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ —Ä–∞–±–æ—Ç–∏ —Å–∞–º–æ –ø—Ä–µ–∑ HTTPS –≤—Ä—ä–∑–∫–∞. –û—Ç–≤–æ—Ä–µ—Ç–µ –≤ –±—Ä–∞—É–∑—ä—Ä —Å https://',
          variant: 'destructive',
        });
        return;
      }

      // Additional mobile-specific checks
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        toast({
          title: '–ú–µ–¥–∏–π–Ω–∏—è—Ç –¥–æ—Å—Ç—ä–ø –Ω–µ —Å–µ –ø–æ–¥–¥—ä—Ä–∂–∞',
          description: '–í–∞—à–∏—è—Ç –º–æ–±–∏–ª–µ–Ω –±—Ä–∞—É–∑—ä—Ä –Ω–µ –ø–æ–¥–¥—ä—Ä–∂–∞ –¥–æ—Å—Ç—ä–ø –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω.',
          variant: 'destructive',
        });
        return;
      }
    }

    if (conversationActive) {
      // End conversation if already active
      endConversation();
      toast({
        title: '–†–∞–∑–≥–æ–≤–æ—Ä—ä—Ç –ø—Ä–∏–∫–ª—é—á–∏',
        description: '–ì–ª–∞—Å–æ–≤–∏—è—Ç —Ä–∞–∑–≥–æ–≤–æ—Ä –±–µ—à–µ —Å–ø—Ä—è–Ω.',
      });
      return;
    }

    // Mobile-specific permission handling
    try {
      console.log('Requesting microphone permission for mobile device...');
      
      // Try to get media stream permission first
      let stream;
      try {
        // Enhanced mobile microphone request with fallbacks
        const audioConstraints = isMobile ? {
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true,
            sampleRate: 16000, // Lower sample rate for mobile
            channelCount: 1
          }
        } : {
          audio: {
            echoCancellation: true,
            noiseSuppression: true,
            autoGainControl: true
          }
        };
        
        stream = await navigator.mediaDevices.getUserMedia(audioConstraints);
        console.log('Microphone access granted');
        
        // Stop the stream immediately - we just needed permission
        stream.getTracks().forEach(track => track.stop());
      } catch (mediaError) {
        console.error('Media permission error:', mediaError);
        
        let errorMessage = '–ú–æ–ª—è, —Ä–∞–∑—Ä–µ—à–µ—Ç–µ –¥–æ—Å—Ç—ä–ø –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞.';
        console.error('MediaError details:', {
          name: mediaError.name,
          message: mediaError.message,
          stack: mediaError.stack,
          isMobile,
          isIOS,
          isAndroid
        });
        
        if (mediaError instanceof Error) {
          switch (mediaError.name) {
            case 'NotAllowedError':
              errorMessage = isMobile 
                ? '–î–æ—Å—Ç—ä–ø—ä—Ç –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –µ –æ—Ç–∫–∞–∑–∞–Ω. –í –Ω–∞—Å—Ç—Ä–æ–π–∫–∏—Ç–µ –Ω–∞ –±—Ä–∞—É–∑—ä—Ä–∞ —Ä–∞–∑—Ä–µ—à–µ—Ç–µ –¥–æ—Å—Ç—ä–ø –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω –∑–∞ —Ç–æ–∑–∏ —Å–∞–π—Ç.'
                : '–î–æ—Å—Ç—ä–ø—ä—Ç –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –µ –æ—Ç–∫–∞–∑–∞–Ω. –ö–ª–∏–∫–Ω–µ—Ç–µ –∏–∫–æ–Ω–∞—Ç–∞ –∑–∞ –∑–∞–∫–ª—é—á–≤–∞–Ω–µ –¥–æ URL-–∞ –∏ —Ä–∞–∑—Ä–µ—à–µ—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω.';
              break;
            case 'NotFoundError':
              errorMessage = isMobile
                ? '–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω. –ü—Ä–æ–≤–µ—Ä–µ—Ç–µ –¥–∞–ª–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ—Ç–æ –∏–º–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω.'
                : '–ú–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –µ –Ω–∞–º–µ—Ä–µ–Ω –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ—Ç–æ.';
              break;
            case 'NotSupportedError':
              errorMessage = isIOS
                ? '–ò–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ Safari –±—Ä–∞—É–∑—ä—Ä –Ω–∞ iOS –∑–∞ –≥–ª–∞—Å–æ–≤–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ.'
                : isAndroid
                  ? '–ò–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ Chrome –±—Ä–∞—É–∑—ä—Ä –Ω–∞ Android –∑–∞ –≥–ª–∞—Å–æ–≤–æ —Ä–∞–∑–ø–æ–∑–Ω–∞–≤–∞–Ω–µ.'
                  : '–ë—Ä–∞—É–∑—ä—Ä—ä—Ç –Ω–µ –ø–æ–¥–¥—ä—Ä–∂–∞ –¥–æ—Å—Ç—ä–ø –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω.';
              break;
            case 'AbortError':
              errorMessage = '–ó–∞—è–≤–∫–∞—Ç–∞ –∑–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω –±–µ—à–µ –ø—Ä–µ–∫—Ä–∞—Ç–µ–Ω–∞ –æ—Ç –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—è.';
              break;
            case 'NotReadableError':
              errorMessage = isMobile
                ? '–ú–∏–∫—Ä–æ—Ñ–æ–Ω—ä—Ç —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞ –æ—Ç –¥—Ä—É–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ. –ó–∞—Ç–≤–æ—Ä–µ—Ç–µ –¥—Ä—É–≥–∏ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∫–æ–∏—Ç–æ –∏–∑–ø–æ–ª–∑–≤–∞—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞.'
                : '–ú–∏–∫—Ä–æ—Ñ–æ–Ω—ä—Ç –Ω–µ –º–æ–∂–µ –¥–∞ –±—ä–¥–µ –¥–æ—Å—Ç—ä–ø–µ–Ω. –í—ä–∑–º–æ–∂–Ω–æ –µ –¥–∞ —Å–µ –∏–∑–ø–æ–ª–∑–≤–∞ –æ—Ç –¥—Ä—É–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ.';
              break;
            case 'OverconstrainedError':
              errorMessage = '–ù–∞—Å—Ç—Ä–æ–π–∫–∏—Ç–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –Ω–µ —Å–∞ –ø–æ–¥–¥—ä—Ä–∂–∞–Ω–∏. –û–ø–∏—Ç–∞–π—Ç–µ —Å –¥—Ä—É–≥ –±—Ä–∞—É–∑—ä—Ä.';
              break;
            default:
              errorMessage = isMobile 
                ? `–ü—Ä–æ–±–ª–µ–º —Å –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ (${mediaError.name}). –û–ø–∏—Ç–∞–π—Ç–µ –¥–∞ —Ä–µ—Ñ—Ä–µ—à–Ω–µ—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü–∞—Ç–∞ –∏–ª–∏ –∏–∑–ø–æ–ª–∑–≤–∞–π—Ç–µ –¥—Ä—É–≥ –±—Ä–∞—É–∑—ä—Ä.`
                : `–ì—Ä–µ—à–∫–∞ –ø—Ä–∏ –¥–æ—Å—Ç—ä–ø –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞: ${mediaError.name}`;
          }
        }
        
        toast({
          title: '–ù—è–º–∞ –¥–æ—Å—Ç—ä–ø –¥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω',
          description: errorMessage,
          variant: 'destructive',
        });
        return;
      }
      
      // If we get here, microphone permission was granted
      setConversationActive(true);
      setIsRecording(true);
      
      toast({
        title: '–ì–ª–∞—Å–æ–≤ —Ä–∞–∑–≥–æ–≤–æ—Ä –∑–∞–ø–æ—á–Ω–∞—Ç',
        description: isMobile 
          ? '–ì–æ–≤–æ—Ä–µ—Ç–µ —Å–µ–≥–∞ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –µ–∑–∏–∫. –ù–∞—Ç–∏—Å–Ω–µ—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∑–∞ –¥–∞ —Å–ø—Ä–µ—Ç–µ.'
          : '–ì–æ–≤–æ—Ä–µ—Ç–µ –Ω–∞ –±—ä–ª–≥–∞—Ä—Å–∫–∏ –µ–∑–∏–∫. –ö–ª–∏–∫–Ω–µ—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –æ—Ç–Ω–æ–≤–æ –∑–∞ –¥–∞ —Å–ø—Ä–µ—Ç–µ.',
      });
      
      // Start speech recognition immediately after getting permission
      setTimeout(() => {
        startListening();
      }, 500);
    } catch (error) {
      console.error('Unexpected error:', error);
      toast({
        title: '–ì—Ä–µ—à–∫–∞',
        description: '–ù–µ–æ—á–∞–∫–≤–∞–Ω–∞ –≥—Ä–µ—à–∫–∞ –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–∏—Ä–∞–Ω–µ –Ω–∞ –≥–ª–∞—Å–æ–≤–∏—è —Ä–∞–∑–≥–æ–≤–æ—Ä.',
        variant: 'destructive',
      });
      return;
    }
  };

  const speakText = async (text: string) => {
    return new Promise<void>((resolve) => {
      if (!('speechSynthesis' in window)) {
        console.log('Speech synthesis not supported');
        resolve();
        return;
      }

      window.speechSynthesis.cancel();
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = 'bg-BG';
      utterance.rate = 0.9;
      utterance.pitch = 1.0;
      
      setIsSpeaking(true);

      utterance.onend = () => {
        setIsSpeaking(false);
        resolve();
        
        // Start listening for next question after AI finishes speaking
        if (conversationActive) {
          setTimeout(() => {
            if (conversationActive) {
              startListening();
            }
          }, 1000); // Wait 1 second after AI finishes speaking
        }
      };

      utterance.onerror = (event) => {
        console.error('Speech synthesis error:', event.error);
        setIsSpeaking(false);
        resolve();
      };

      window.speechSynthesis.speak(utterance);
    });
  };

  const stopSpeaking = () => {
    window.speechSynthesis.cancel();
    setIsSpeaking(false);
  };

  const quickQuestions = [
    "How is scoring calculated?",
    "Find nearby vegan places",
    "Allergy-friendly options",
    "Best vegan restaurants",
    "Explain vegan score breakdown"
  ];

  return (
    <div className="min-h-screen bg-white flex flex-col pb-20">
      {/* Header with Back Link */}
      <div className="sticky top-0 bg-white border-b border-gray-200 z-10">
        <div className="max-w-4xl mx-auto px-4 py-4">
          <div className="flex items-center justify-between">
            <div className="flex items-center">
              <div className="w-10 h-10 bg-vegan-green rounded-full flex items-center justify-center mr-3">
                <i className="fas fa-robot text-white"></i>
              </div>
              <div>
                <h1 className="text-lg font-poppins font-semibold">VeganAI Assistant</h1>
                <p className="text-sm text-vegan-green">Online</p>
              </div>
            </div>
            <div className="flex items-center space-x-3">
              <button 
                onClick={clearChat}
                className="text-gray-500 hover:text-gray-700 font-medium text-sm"
                title="Clear chat history"
              >
                Clear
              </button>
              <button 
                onClick={() => setLocation('/')}
                className="text-gray-600 hover:text-gray-800 font-medium"
              >
                Back
              </button>
            </div>
          </div>
        </div>
      </div>
      
      {/* Chat Messages Container */}
      <div className="flex-1 overflow-y-auto p-4 max-w-4xl mx-auto w-full">
        {/* Voice Conversation Status */}
        {conversationActive && (
          <div className="mb-4 p-3 bg-blue-50 border border-blue-200 rounded-lg text-center">
            <p className="text-sm text-blue-700 font-medium">
              üéôÔ∏è –ì–ª–∞—Å–æ–≤ —Ä–∞–∑–≥–æ–≤–æ—Ä –∞–∫—Ç–∏–≤–µ–Ω - {isListening ? '–°–ª—É—à–∞–º...' : isSpeaking ? '–ì–æ–≤–æ—Ä—è...' : '–ì–æ—Ç–æ–≤'}
            </p>
            <p className="text-xs text-blue-600 mt-1">
              –†–∞–∑–≥–æ–≤–æ—Ä—ä—Ç —â–µ –ø—Ä–∏–∫–ª—é—á–∏ —Å–ª–µ–¥ {conversationActive ? '7' : '5'} —Å–µ–∫—É–Ω–¥–∏ –±–µ–∑–¥–µ–π—Å—Ç–≤–∏–µ
            </p>
            <p className="text-xs text-blue-500 mt-1">
              üí° –ö–ª–∏–∫–Ω–µ—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –æ—Ç–Ω–æ–≤–æ –∑–∞ –¥–∞ —Å–ø—Ä–µ—Ç–µ —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
            </p>
          </div>
        )}

        {/* Quick Action Questions */}
        {!conversationActive && (
          <div className="grid grid-cols-1 md:grid-cols-2 gap-3 mb-4">
            {quickQuestions.map((question, index) => (
              <Button
                key={index}
                variant="outline"
                className="text-left justify-start h-auto p-3 text-sm"
                onClick={() => handleQuickQuestion(question)}
              >
                {question}
              </Button>
            ))}
          </div>
        )}

        <div className="space-y-4">
          {messages.map((message, index) => (
            <div
              key={index}
              className={`chat-message flex items-start ${
                message.role === 'user' ? 'justify-end' : ''
              }`}
            >
              {message.role === 'assistant' && (
                <div className={`w-8 h-8 rounded-full flex items-center justify-center mr-3 flex-shrink-0 transition-colors ${
                  isSpeaking ? 'bg-blue-500 animate-pulse' : 'bg-vegan-green'
                }`}>
                  <i className="fas fa-robot text-white text-sm"></i>
                </div>
              )}
              <div
                className={`rounded-2xl p-4 max-w-xs md:max-w-sm ${
                  message.role === 'user'
                    ? 'bg-vegan-green text-white rounded-tr-md'
                    : 'bg-vegan-light-green rounded-tl-md'
                }`}
              >
                <div className="flex flex-col">
                  <p className={`font-opensans ${
                    message.role === 'user' ? 'text-white' : 'text-gray-800'
                  }`}>
                    {message.content}
                  </p>
                  {message.role === 'assistant' && (
                    <div className="flex items-center mt-2 space-x-2">
                      <button
                        onClick={() => speakText(message.content)}
                        disabled={isSpeaking}
                        className="text-xs text-gray-500 hover:text-vegan-green transition-colors flex items-center"
                        title="Speak message"
                      >
                        <i className="fas fa-volume-up mr-1"></i>
                        Play
                      </button>
                      {isSpeaking && (
                        <button
                          onClick={stopSpeaking}
                          className="text-xs text-red-500 hover:text-red-700 transition-colors flex items-center"
                          title="Stop speaking"
                        >
                          <i className="fas fa-stop mr-1"></i>
                          Stop
                        </button>
                      )}
                    </div>
                  )}
                </div>
              </div>
            </div>
          ))}
          
          {chatMutation.isPending && (
            <div className="flex items-start">
              <div className="w-8 h-8 rounded-full bg-vegan-green flex items-center justify-center mr-3 flex-shrink-0 animate-pulse">
                <i className="fas fa-robot text-white text-sm"></i>
              </div>
              <div className="bg-vegan-light-green rounded-2xl rounded-tl-md p-4 max-w-xs md:max-w-sm">
                <div className="flex space-x-1">
                  <div className="w-2 h-2 bg-vegan-green rounded-full animate-pulse"></div>
                  <div className="w-2 h-2 bg-vegan-green rounded-full animate-pulse" style={{ animationDelay: '0.2s' }}></div>
                  <div className="w-2 h-2 bg-vegan-green rounded-full animate-pulse" style={{ animationDelay: '0.4s' }}></div>
                </div>
              </div>
            </div>
          )}
        </div>
      </div>

      {/* Fixed bottom section with voice button and text input */}
      <div className="fixed bottom-0 left-0 right-0 bg-white border-t border-gray-200 p-4">
        <div className="max-w-4xl mx-auto">
          {/* Voice Recording Button */}
          <div className="flex items-center justify-center mb-6">
            <button
              onClick={handleVoiceRecording}
              disabled={chatMutation.isPending || isSpeaking}
              className={`
                p-6 rounded-full border-2 transition-all duration-200 text-2xl
                ${conversationActive
                  ? 'bg-red-500 border-red-500 text-white hover:bg-red-600'
                  : isRecording
                    ? 'bg-red-500 border-red-500 text-white animate-pulse'
                    : isSpeaking
                      ? 'bg-orange-500 border-orange-500 text-white'
                      : 'bg-green-500 border-green-500 text-white hover:bg-green-600'
                }
                disabled:opacity-50 disabled:cursor-not-allowed
                touch-manipulation active:scale-95
              `}
              style={{ 
                WebkitTapHighlightColor: 'transparent',
                WebkitUserSelect: 'none',
                userSelect: 'none'
              }}
            >
              üé§
            </button>
          </div>

          {/* Status Messages */}
          <div className="text-center mb-4">
            {isListening && (
              <p className="text-sm text-blue-600 animate-pulse">üéôÔ∏è –°–ª—É—à–∞–º...</p>
            )}
            {isSpeaking && (
              <p className="text-sm text-orange-600 animate-pulse">üó£Ô∏è –ì–æ–≤–æ—Ä—è...</p>
            )}
            {conversationActive && !isListening && !isSpeaking && (
              <p className="text-sm text-green-600">‚úÖ –ì–æ—Ç–æ–≤ –∑–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä</p>
            )}
            {!conversationActive && (
              <p className="text-sm text-gray-500">–ö–ª–∏–∫–Ω–µ—Ç–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –∑–∞ –≥–ª–∞—Å–æ–≤ —Ä–∞–∑–≥–æ–≤–æ—Ä</p>
            )}
          </div>

          {/* Text Input Form */}
          <form onSubmit={handleSubmit} className="flex gap-3">
            <Textarea
              value={currentMessage}
              onChange={(e) => setCurrentMessage(e.target.value)}
              placeholder="–ù–∞–ø–∏—à–µ—Ç–µ —Å—ä–æ–±—â–µ–Ω–∏–µ..."
              className="flex-1 resize-none min-h-[44px] max-h-[120px]"
              onKeyDown={(e) => {
                if (e.key === 'Enter' && !e.shiftKey) {
                  e.preventDefault();
                  handleSubmit(e);
                }
              }}
            />
            <Button 
              type="submit" 
              disabled={!currentMessage.trim() || chatMutation.isPending}
              className="bg-vegan-green hover:bg-vegan-green/90 text-white px-6"
            >
              Send
            </Button>
          </form>
        </div>
      </div>
    </div>
  );
}